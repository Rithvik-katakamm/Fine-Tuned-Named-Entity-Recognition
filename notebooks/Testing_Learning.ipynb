{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named Entitiy Recognition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets get some text in here (this sentence is questionable but eh)\n",
    "text = 'Rithvik is playing basketball at Northeastern University' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity: diabetes, Label: B-Disease_disorder, Score: 0.9951\n",
      "Entity: met, Label: B-Medication, Score: 0.9999\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load a biomedical NER model that is already fine-tuned\n",
    "ner_pipeline = pipeline(\"ner\", model=\"d4data/biomedical-ner-all\", tokenizer=\"d4data/biomedical-ner-all\")\n",
    "\n",
    "# Test text\n",
    "text = \"The patient was diagnosed with diabetes and prescribed Metformin.\"\n",
    "\n",
    "# Run inference\n",
    "entities = ner_pipeline(text)\n",
    "\n",
    "# Display results\n",
    "for entity in entities:\n",
    "    print(f\"Entity: {entity['word']}, Label: {entity['entity']}, Score: {entity['score']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cpu\n",
      "Requirement already satisfied: transformers in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (4.45.2)\n",
      "Requirement already satisfied: datasets in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (3.2.0)\n",
      "Requirement already satisfied: torch in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (2.5.1)\n",
      "Collecting torchvision\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torchvision-0.21.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: torchaudio in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (2.5.1)\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement seqeval (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for seqeval\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers datasets torch torchvision torchaudio seqeval accelerate --index-url https://download.pytorch.org/whl/cpu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "data = load_dataset(\"ncbi_disease\")\n",
    "\n",
    "print(data[\"train\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43a0f645831d4b8f956f61b4b17fd8e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/284k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3a055c44a9346c08cd7894c56ac01ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/51.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46cdc9bd21b441c49d3bd8288681e1c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/52.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2601cae5a78f4956a88a0216ad9c3e95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/5433 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70692fdcfa3b4afea0e35e030cf442fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/924 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dafcd69a9c9748608a4ff394551b4ebd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/941 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset splits: DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'tokens', 'ner_tags'],\n",
      "        num_rows: 5433\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['id', 'tokens', 'ner_tags'],\n",
      "        num_rows: 924\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'tokens', 'ner_tags'],\n",
      "        num_rows: 941\n",
      "    })\n",
      "})\n",
      "Sample from training split: {'id': '0', 'tokens': ['Identification', 'of', 'APC2', ',', 'a', 'homologue', 'of', 'the', 'adenomatous', 'polyposis', 'coli', 'tumour', 'suppressor', '.'], 'ner_tags': [0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the NCBI Disease dataset\n",
    "dataset = load_dataset(\"ncbi_disease\")\n",
    "\n",
    "# Inspect the dataset structure\n",
    "print(\"Dataset splits:\", dataset)\n",
    "print(\"Sample from training split:\", dataset[\"train\"][0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
